{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy Introduction for NLP | Rule Based Phrase Text Extraction and Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy-lookups-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-based matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-based matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say we want to enable spaCy to find a combination of three tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A token whose lowercase form matches “hello”, e.g. “Hello” or “HELLO”.\n",
    "2. A token whose `is_punct` flag is set to `True`, i.e. any punctuation.\n",
    "3. A token whose lowercase form matches “world”, e.g. “World” or “WORLD”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing patterns, keep in mind that each dictionary represents one token. If spaCy’s tokenization doesn’t match the tokens defined in a pattern, the pattern is not going to produce any results. When developing complex patterns, make sure to check examples against spaCy’s tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Hello World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello World!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For spacy creating matcher and pattern for regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\": \"hello\", 'OP':'?'}, {\"IS_PUNCT\": True, 'OP':'?'}, {\"LOWER\": \"world\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('HelloWorldFinder', None, pattern)#(Any name,a call back function, pattern )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14022650268102919206, 0, 3),\n",
       " (14022650268102919206, 1, 3),\n",
       " (14022650268102919206, 2, 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches #match id, start,end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The 3 tuples as result indicates:\n",
    "    i)'Hello' is found\n",
    "    ii)'World' is found\n",
    "    iii)'Hello world' is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Lets create a function to find all details about matcher i.e, match_id, string_id, start, end, span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14022650268102919206 HelloWorldFinder 0 3 Hello, world\n",
      "14022650268102919206 HelloWorldFinder 1 3 , world\n",
      "14022650268102919206 HelloWorldFinder 2 3 world\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://explosion.ai/demos/matcher "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, only matching tokens and token attributes isn’t enough – for example, you might want to match different spellings of a word, without having to add a new pattern for each spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
    "\n",
    "<tr ><td><span >\\d</span></td><td>A digit</td><td>file_\\d\\d</td><td>file_25</td></tr>\n",
    "\n",
    "<tr ><td><span >\\w</span></td><td>Alphanumeric</td><td>\\w-\\w\\w\\w</td><td>A-b_1</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >\\s</span></td><td>White space</td><td>a\\sb\\sc</td><td>a b c</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >\\D</span></td><td>A non digit</td><td>\\D\\D\\D</td><td>ABC</td></tr>\n",
    "\n",
    "<tr ><td><span >\\W</span></td><td>Non-alphanumeric</td><td>\\W\\W\\W\\W\\W</td><td>*-+=)</td></tr>\n",
    "\n",
    "<tr ><td><span >\\S</span></td><td>Non-whitespace</td><td>\\S\\S\\S\\S</td><td>Yoyo</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
    "\n",
    "<tr ><td><span >+</span></td><td>Occurs one or more times</td><td>\tVersion \\w-\\w+</td><td>Version A-b1_1</td></tr>\n",
    "\n",
    "<tr ><td><span >{3}</span></td><td>Occurs exactly 3 times</td><td>\\D{3}</td><td>abc</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >{2,4}</span></td><td>Occurs 2 to 4 times</td><td>\\d{2,4}</td><td>123</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >{3,}</span></td><td>Occurs 3 or more</td><td>\\w{3,}</td><td>anycharacters</td></tr>\n",
    "\n",
    "<tr ><td><span >\\*</span></td><td>Occurs zero or more times</td><td>A\\*B\\*C*</td><td>AAACC</td></tr>\n",
    "\n",
    "<tr ><td><span >?</span></td><td>Once or none</td><td>plurals?</td><td>plural</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my phone number is 1256. Ohh its wrong! Correct one is 1256348790. call me!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(55, 65), match='1256348790'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d{10}', text)#only 10 digit number to be find out\n",
    "#start and end position and matched keyword is also given like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(19, 23), match='1256'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d{4}', text)#Only 4 digit words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"123  45455 789956665565 122233 12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123', '45455', '7899566655', '122233']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{3,10}', text)#findall searches throughout the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my phone number is 1256. Ohh its wrong! Correct one is 1256348790. call me!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'number', '1256', 'wrong', 'Correct', '1256348790', 'call']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w{4,}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='my'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r'\\w{2,10}', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Difference between search, match and between:\n",
    "    \n",
    "    match--> finds only once and in the beginning only\n",
    "    search-->finds anywhere but only once\n",
    "    findall-->finds throughout the text and serches many times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3. wildcard text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ct ', 'cal']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'c..', text)#not a wildcard #only any word starting with 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this is cat but not that. i want hat and cat na both\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'hat', 'wan', 'hat', ' an', 'cat', 'na ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'.a.', text)#not a wildcard #only any word which contains 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hi thanks for watching <3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d$', text)#searches everywhere many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(24, 25), match='3'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d$', text)#finds only once #pattern is ending with 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '3 hi thanks for watching <3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^\\d', text)#starting with '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 hi thanks for watching <3'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' hi thanks for watching <']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^\\d]+', text) #Exclude digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hi 33 thanks for watching <3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33', '3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^\\D]+', text)#Not from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"you can get free-videos on Google-youtube\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['free-videos', 'Google-youtube']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[\\w]+-[\\w]+', text)#words containing hyphen(-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression in SpaCy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match different spellings of token texts `pattern = [{\"TEXT\": {\"REGEX\": \"deff?in[ia]tely\"}}]`\n",
    "\n",
    "\n",
    "Match tokens with fine-grained POS tags starting with 'V' `pattern = [{\"TAG\": {\"REGEX\": \"^V\"}}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Google announced a new Pixel at Google I/O Google I/O is a great place to get all updates from Google.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google announced a new Pixel at Google I/O Google I/O is a great place to get all updates from Google.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'TEXT':'Google'}, {'TEXT': 'I'}, {'TEXT':'/'}, {'TEXT':'O'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_method(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    entity = doc[start:end]\n",
    "    print(entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Google', callback_method, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google I/O\n",
      "Google I/O\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(11578853341595296054, 6, 10), (11578853341595296054, 10, 14)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find word Google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'TEXT':'Google'}, {'TEXT': 'I', 'OP': '?'}, {'TEXT':'/', 'OP': '?'}, {'TEXT':'O', 'OP': '?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_method(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    entity = doc[start:end]\n",
    "    print(entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Google', callback_method, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PArt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Linguistic Annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you’re analyzing user comments and you want to find out what people are saying about Facebook. You want to start off by finding adjectives following “Facebook is” or “Facebook was”. This is obviously a very rudimentary solution, but it’ll be fast, and a great way to get an idea for what’s in your data. Your pattern could look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates to a token whose lowercase form matches “facebook” (like Facebook, facebook or FACEBOOK), followed by a token with the lemma “be” (for example, is, was, or ‘s), followed by an optional adverb, followed by an adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/api/annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)#loading nlp vocabulary to matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sents = []#breaking a doc into sentences based on matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]#pattern creation in spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_method_fb(matcher, doc, i, matches):\n",
    "    matched_id, start, end = matches[i]\n",
    "    span = doc[start:end]\n",
    "    sent = span.sent\n",
    "    \n",
    "    match_ents = [{\n",
    "        'start':span.start_char - sent.start_char, # a dictionary to\n",
    "        'end': span.end_char - sent.start_char,\n",
    "        'label': 'MATCH'\n",
    "    }]\n",
    "    \n",
    "    matched_sents.append({'text': sent.text, 'ents':match_ents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"fbreviewer\", callback_method_fb, pattern)#using matcher to see the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I'd say that Facebook is evil. – Facebook is pretty cool, right?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8979314357719909335, 4, 7), (8979314357719909335, 9, 13)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"I'd say that Facebook is evil.\",\n",
       "  'ents': [{'start': 13, 'end': 29, 'label': 'MATCH'}]},\n",
       " {'text': '– Facebook is pretty cool, right?',\n",
       "  'ents': [{'start': 2, 'end': 25, 'label': 'MATCH'}]}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I'd say that \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is evil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ".</div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">– \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook is pretty cool\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
       "</mark>\n",
       ", right?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(matched_sents, style='ent', manual = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting phone numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phone numbers can have many different formats and matching them is often tricky. During tokenization, spaCy will leave sequences of numbers intact and only split on whitespace and punctuation. This means that your match pattern will have to look out for number sequences of a certain length, surrounded by specific punctuation – depending on the national conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to match like this `(123) 4567 8901 or (123) 4567-8901`\n",
    "\n",
    "`[{\"ORTH\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"ORTH\": \")\"}, {\"SHAPE\": \"dddd\"}, {\"ORTH\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"ORTH\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"ORTH\": \")\"}, {\"SHAPE\": \"dddd\"}, {\"ORTH\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}]\n",
    "#pattern for phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"PhoneNumber\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Call me at (123) 4560-7890 and (990) 3453-4325\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'at', '(', '123', ')', '4560', '-', '7890', 'and', '(', '990', ')', '3453', '-', '4325']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7978097794922043545, 3, 9), (7978097794922043545, 10, 16)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matcher(doc) #applying matcher over the text \n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123) 4560-7890\n",
      "(990) 3453-4325\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text) #this give the number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Email Address Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"TEXT\": {\"REGEX\": \"[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+\"}}]#pattern for email id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Email\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Email me at kishan.pandey1352@gmail.com and ks5pandey@gmail.com amd ks5pandey@hotmail.com or kishan.@medtronic.com \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11010771136823990775, 3, 4),\n",
       " (11010771136823990775, 5, 6),\n",
       " (11010771136823990775, 7, 8),\n",
       " (11010771136823990775, 9, 10)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches#match id, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kishan.pandey1352@gmail.com\n",
      "ks5pandey@gmail.com\n",
      "ks5pandey@hotmail.com\n",
      "kishan.@medtronic.com\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)#this brings out all the email ids from the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags and emoji on social media "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media posts, especially tweets, can be difficult to work with. They’re very short and often contain various emoji and hashtags. By only looking at the plain text, you’ll lose a lot of valuable semantic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you’ve extracted a large sample of social media posts on a specific topic, for example posts mentioning a brand name or product. As the first step of your data exploration, you want to filter out posts containing certain emoji and use them to assign a general sentiment score, based on whether the expressed emotion is positive or negative, e.g. 😀 or 😞. You also want to find, merge and label hashtags like #MondayMotivation, to be able to ignore or analyze them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, spaCy’s tokenizer will split emoji into separate tokens. This means that you can create a pattern for one or more emoji tokens. Valid hashtags usually consist of a #, plus a sequence of ASCII characters with no whitespace, making them easy to match as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emoji = [\"😀\", \"😃\", \"😂\", \"🤣\", \"😊\", \"😍\"]  # Positive emoji \n",
    "neg_emoji = [\"😞\", \"😠\", \"😩\", \"😢\", \"😭\", \"😒\"]  # Negative emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😀', '😃', '😂', '🤣', '😊', '😍']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patterns to match one or more emoji tokens\n",
    "pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n",
    "neg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ORTH': '😀'}],\n",
       " [{'ORTH': '😃'}],\n",
       " [{'ORTH': '😂'}],\n",
       " [{'ORTH': '🤣'}],\n",
       " [{'ORTH': '😊'}],\n",
       " [{'ORTH': '😍'}]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ORTH': '😞'}],\n",
       " [{'ORTH': '😠'}],\n",
       " [{'ORTH': '😩'}],\n",
       " [{'ORTH': '😢'}],\n",
       " [{'ORTH': '😭'}],\n",
       " [{'ORTH': '😒'}]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(matcher, doc, i, matches): # a function to compare the emojis as positive or ngative\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id] == 'HAPPY':\n",
    "        doc.sentiment += 0.1\n",
    "    elif doc.vocab.strings[match_id] == 'SAD':\n",
    "        doc.sentiment -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"HAPPY\", label_sentiment, *pos_patterns)\n",
    "matcher.add('SAD', label_sentiment, *neg_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('HASHTAG', None, [{'TEXT': '#'}, {'IS_ASCII': True}]) #no sentiment for '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hello world 😀 #BSE_INDIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAPPY 😀\n",
      "HASHTAG #BSE_INDIA\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = doc.vocab.strings[match_id]  # Look up string ID\n",
    "    span = doc[start:end]\n",
    "    print(string_id, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient phrase matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to match large terminology lists, you can also use the PhraseMatcher and create Doc objects instead of token patterns, which is much more efficient overall. The Doc patterns can contain single or multiple tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['BARAC OBAMA', 'ANGELA MERKEL', 'WASHINGTON D.C.']#terms to be matched in a given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [nlp.make_doc(text) for text in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BARAC OBAMA, ANGELA MERKEL, WASHINGTON D.C.]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern #pattern created out the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('term', None, *pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"German Chancellor ANGELA MERKEL and US President BARAC OBAMA \"\n",
    "          \"converse in the Oval Office inside the White House in  WASHINGTON D.C.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "German Chancellor ANGELA MERKEL and US President BARAC OBAMA converse in the Oval Office inside the White House in  WASHINGTON D.C."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGELA MERKEL\n",
      "BARAC OBAMA\n",
      "WASHINGTON D.C.\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text) This gives out which pattern is present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4519742297340331040, 2, 4),\n",
       " (4519742297340331040, 7, 9),\n",
       " (4519742297340331040, 20, 22)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches #match id, start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Rule Based Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EntityRuler is an exciting new component that lets you add named entities based on pattern dictionaries, and makes it easy to combine rule-based and statistical named entity recognition for even more powerful models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entity Patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity patterns are dictionaries with two keys: \"label\", specifying the label to assign to the entity if the pattern is matched, and \"pattern\", the match pattern. The entity ruler accepts two types of patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Phrase Pattern\n",
    "`{\"label\": \"ORG\", \"pattern\": \"Apple\"}`\n",
    "- Token Pattern `{\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the entity ruler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EntityRuler is a pipeline component that’s typically added via nlp.add_pipe. When the nlp object is called on a text, it will find matches in the doc and add them as entities to the doc.ents, using the specified pattern label as the entity label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') #loading small english library of Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = EntityRuler(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"TCS\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]},\n",
    "             {\"label\": \"GPE\", \"pattern\": \"Siwan\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ORG', 'pattern': 'TCS'},\n",
       " {'label': 'GPE', 'pattern': [{'LOWER': 'san'}, {'LOWER': 'francisco'}]},\n",
       " {'label': 'GPE', 'pattern': 'Siwan'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns# my custom patterns are added for future NER in NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)#creating rule using custom patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I work in TCS and live in Siwan and have a longing to visit San Francisco.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I work in TCS and live in Siwan and have a longing to visit San Francisco."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS ORG\n",
      "Siwan GPE\n",
      "San Francisco GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
